# -*- coding: utf-8 -*-
"""gans01_pipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15UwRZ7o9GLcCg0FuYrVT9x1lhL0vkbhL
"""

import cv2
import os
from os import listdir
import sys
import argparse
from posixpath import join
import shutil

import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scipy

!python -m pip install face_recognition
import face_recognition as fr

!python -m pip install image-quality
import imquality.brisque as brisque

import imutils
import time
from imutils.object_detection import non_max_suppression
from google.colab.patches import cv2_imshow

from datetime import datetime
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

!pip uninstall -y Pillow
!pip install Pillow==9.0.0
!pip uninstall -y imgaug
!pip install imgaug==0.2.5

import PIL
print('PIL', PIL.__version__)
from PIL import Image, ImageStat

!pip uninstall -y Pillow
!pip install Pillow==9.0.0

print(PIL.__version__)

from google.colab import drive
drive.mount('/content/drive')

#Append the directory to your python path
prefix = '/content/drive/My Drive/'
# modify customized_path
customized_path = 'gans_2022/'
proj_path = prefix + customized_path
sys.path.append(proj_path)
print(sys.path)

print('Path to training data: {}'.format(proj_path))

#TODO: Standardize input/output paths to make more sense.

class Pipeline():
  def __init__(self, proj_path='', input_folder='input/', output_folder='output/', \
               resize=300, blur_thresh=30, qual_thresh=70, text_thresh=0.35) -> None:

    self.input_path = os.path.join(proj_path, input_folder)
    self.output_path = os.path.join(proj_path, output_folder)
    self.size = resize

    self.valid_ext = ['.jpg', '.jpeg', '.png', '.tif', '.tiff', '.bmp', '.gif',\
               '.eps', '.raw', '.cr2', '.nef', '.orf', '.sr2','.webp']
    self.blur_thresh = blur_thresh
    self.blurry_input = []
    self.qual_thresh = qual_thresh
    self.text_thresh = text_thresh

    self.allfiles_input = [] #directory paths
    self.validimg_input = [] #directory paths
    self.acc_img = [] #directory paths
    self.rej_img = [] #directory paths
    self.display_img = [] #PIL Image objects

    self.input_widths = [] #int
    self.input_heights = [] #int
    self.input_formats = set() #str

    self.img_dict = dict()

  def filter(self, input_path, output_path, size):
    """
      Given input data files, processes and sorts them according to usability. 
      Main data pipeline function.

      Params:
        input_path: Directory path to input images.
        output_path: Directory path to output images.
        size: Desired length of square output image's edge.
    """
    self.walk(self.input_path, self.allfiles_input)
    print("NUMBER OF POTENTIAL INPUTS: ", str(len(self.allfiles_input)))

    img_num = 0
    for img in self.allfiles_input:
      # ~~~~~~~~~~~~~~~~ Start Loop ~~~~~~~~~~~~~~~~
      if self.reject_image(img, self.input_path, output_path, size, self.blurry_input): continue
      
      cur_name = os.path.basename(os.path.normpath(img))
      out_name = str(img_num).zfill(6)+'.png'
      print(cur_name, "ACCEPTED as", out_name)

      #assemble dict ~~~
      self.add_entry(img, out_name, self.img_dict)
      acc_folder = os.path.join(output_path, "accepted")
      acc_img_path = os.path.join(acc_folder, out_name)

      #Image handling ~~~
      img_standard = self.img_standardize(img, size)
      self.display_img.append(img_standard)
      img_standard.save(acc_img_path)
      
      #Path handling ~~~
      self.acc_img.append(acc_img_path)

      #Update valid img number
      img_num += 1
      # ~~~~~~~~~~~~~~~~ End Loop ~~~~~~~~~~~~~~~~

    #save to json to /output ~~~
    self.writejson(self.output_path)

    #save log file
    self.writelog(self.validimg_input, self.input_widths, self.input_heights,
             self.input_formats, len(self.acc_img))

    # Peek at cropped images
    self.display_accepted(self.display_img)
    
    # Returns dictionary
    return self.img_dict

#~~~~~~~~~~~~ Helper functions ~~~~~~~~~~~~~~~~~
  def display_accepted(self, displayimg):
    """
      Displays images that passed the acceptance criteria.

      Params:
        displayimg: List of Image objects to plot.
    """
    plt.figure(figsize=(10,10))
    for i in range(len(displayimg)):
      plt.subplot(len(displayimg), len(displayimg), i+1)
      plt.axis('off')
    plt.show()

  def walk(self, input_path, files):
    """
      Searches for and collects directory pathways to files.

      Params:
        input_path: Directory path to input images.
        files: A list to store directory paths to valid files.

      Returns:????
        files: A list of pathways to valid files.
    """
    input_list = os.listdir(input_path)
    for item in input_list:
      if item == '.blurry' or item == '.sharp':
        continue
      if os.path.isdir(os.path.join(input_path,item)):
        self.walk(os.path.join(input_path, item), files)
      else:
        files.append(os.path.join(input_path, item))

  def img_standardize(self, cur_img, size):
    """
      A function that crops and resizes the image being examined.

      Params:
        im: The image being standardized.
        size: The desired size to which to resize the input image to.
      Returns:
        img: PIL Image object of the standardized image.
    """
    img = Image.open(cur_img)
    width, height = img.size

    if (width > height):
      left_start = (width-height)/2
      img = img.crop((left_start, 0, left_start+height,height))
    elif (height > width):
      top_start = (height-width)/2
      img = img.crop((0, top_start, width, top_start+width))

    img = img.resize((size,size))
    return img

  def blur_detection(self, input_path, thresh=30, split=True, v=True):
    """
      A function that detects and designates images as having an unacceptable
      amount of blurring.

      Params:
        input_path: Directory path to input images.
        thresh: Blurring threshold at which to classify as "blurry."
        split: Boolean denoting whether or nto to copy blurry images into a
          "blurry" subdirectory.
        verbose: Track progress verbosely.

      Returns:
        A list of image NAMES classified as blurry. MAKE PATHS?
    """
    input_list = []
    self.walk(input_path, input_list)
    input_list.sort()

    if split:
      shutil.rmtree(os.path.join(input_path, '.blurry'))
      shutil.rmtree(os.path.join(input_path, '.sharp'))
      blurry_path = os.path.join(input_path, '.blurry')
      sharp_path = os.path.join(input_path, '.sharp')
      os.makedirs(blurry_path, exist_ok=True)
      os.makedirs(sharp_path, exist_ok=True)

    lpcs = []
    for img_path in input_list:
      cur_name = os.path.basename(os.path.normpath(img_path))
      if v:
        print(cur_name, img_path)
      try:
        img_cv2 = cv2.imread(img_path)
        img_gray = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2GRAY)
        lpc = cv2.Laplacian(img_gray, cv2.CV_64F).var()
        lpcs.append(lpc)
        if v:
          print(lpc)
        if split:
          if lpc >= thresh:
            cv2.imwrite(os.path.join(sharp_path, cur_name), img_cv2)
          else:
            cv2.imwrite(os.path.join(blurry_path, cur_name), img_cv2)
      except:
        print("NOTE: " + cur_name + " is not an image. Continuing.")

    #return lpcs
    return os.listdir(blurry_path)

  def text_detection(self, cur_img, confidence):
    """
      Detects and recognizes allged text that appears in images.

      Params:
        cur_img: Directory path of the current image being assessed.
        confidence: Probability as a measure of sensitivity to which text
        is detected in an image.

      Returns:
        The number of distinct text objects recognized.
    """

    """PATH-ORIENTED DETECTION: CLASSIFY WHICH IMAGES HAVE TEXT, STORE PATHS TO CHECK"""
    #text_path = os.path.join(input_path, '.text')
    #shutil.rmtree(text_path)
    #os.makedirs(text_path, exist_ok=True)
    
    #input_list = []
    #self.walk(input_path, input_list)
    #input_list.sort()

    #Loop thru input_list, detect text

    """IMAGE-ORIENTED DETECTION: CLASSIFY SPECIFIC IMAGE AS HAVING TEXT"""
    cur_name = os.path.basename(os.path.normpath(cur_img))

    east_path = os.path.join(proj_path, 'frozen_east_text_detection.pb')
    wid_new = 320
    hei_new = 320 #Adjustable

    img = cv2.imread(cur_img)
    img_orig = img.copy()

    (hei_orig, wid_orig) = img.shape[:2]
    wid_ratio = wid_orig / float(wid_new)
    hei_ratio = hei_orig / float (hei_new)

    img = cv2.resize(img, (wid_new, hei_new))
    #Grab dimensions?

    layerNames = [
      "feature_fusion/Conv_7/Sigmoid",
      "feature_fusion/concat_3"]

    net = cv2.dnn.readNet(east_path)
    blob = cv2.dnn.blobFromImage(img, 1.0, (wid_new, hei_new), \
      (123.68, 116.78, 103.94), swapRB=True, crop=False)
    net.setInput(blob)
    (scores, geometry) = net.forward(layerNames)

    (numRows, numCols) = scores.shape[2:4]
    rects = []
    confidences = []

    for y in range(0, numRows):
      # extract the scores (probabilities), followed by the geometrical data
      scoresData = scores[0, 0, y]
      xData0 = geometry[0, 0, y]
      xData1 = geometry[0, 1, y]
      xData2 = geometry[0, 2, y]
      xData3 = geometry[0, 3, y]
      anglesData = geometry[0, 4, y]

      # loop over the number of columns
      for x in range(0, numCols):
        # if our score does not have sufficient probability, ignore it
        if scoresData[x] < confidence:
          continue
        # compute the offset factor as our resulting feature maps will 4x smaller
        (offsetX, offsetY) = (x * 4.0, y * 4.0)
        # extract the rotation angle for the prediction and then compute sin, cos
        angle = anglesData[x]
        cos = np.cos(angle)
        sin = np.sin(angle)
        # use the geometry volume to derive the width and height of pred box
        h = xData0[x] + xData2[x]
        w = xData1[x] + xData3[x]
        # compute both the starting and ending (x, y)-coordinates for pred box
        endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))
        endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))
        startX = int(endX - w)
        startY = int(endY - h)
        # add the bounding box coordinates and probability score to resp. lists
        rects.append((startX, startY, endX, endY))
        confidences.append(scoresData[x])

    boxes = non_max_suppression(np.array(rects), probs=confidences)
    for (startX, startY, endX, endY) in boxes:
      # scale the bounding box coordinates based on the respective ratios
      startX = int(startX * wid_ratio)
      startY = int(startY * hei_ratio)
      endX = int(endX * wid_ratio)
      endY = int(endY * hei_ratio)
      # draw the bounding box on the image
      cv2.rectangle(img_orig, (startX, startY), (endX, endY), (0, 255, 0), 2)

    cv2.imwrite(os.path.join(os.path.join(self.input_path, '.textdetection'), cur_name), img_orig)
    return len(rects)
    #return os.listdir(text_path)

  def writelog(self, validimg_inputlist, widths, heights, formats, acc):
    """
      Writes a text file containing statistics about the input dataset.

      Params:
        validimg_inputlist: list of valid input image paths
        widths: list of image widths
        heights: list of image heights
        formats: set of image formats that appear
        acc: number of accepted images
    """
    datetime_exc = datetime.now() #Date and time of finished execution
    num = len(validimg_inputlist)
    minw = np.min(widths)
    maxw = np.max(widths)
    minh = np.min(heights)
    maxh = np.max(heights)
    avw = np.average(widths)
    avh = np.average(heights)
    rej = num - acc
    percentage = (acc / (acc + rej))

    #Write stuff to file
    log_path = os.path.join(proj_path, '.logs')
    with open(os.path.join(log_path, 'log.txt'), 'w') as f:
      f.write("Latest successful execution:")
      f.write('\n')
      
      f.write(join("Number of valid images:", str(num)))
      f.write('\n')
      f.write('\n')

      f.write(join('Minimum input width:', str(minw)))
      f.write('\n')
      f.write(join('Maximum input width:', str(maxw)))
      f.write('\n')
      f.write('\n')

      f.write(join('Minimum input height:', str(minh)))
      f.write('\n')
      f.write(join('Maximum input height:', str(maxh)))
      f.write('\n')
      f.write('\n')

      f.write(join('Average input width:', str(avw)))
      f.write('\n')
      f.write(join('Average input height:', str(avh)))
      f.write('\n')
      f.write('\n')

      f.write(join('Percentage of accepted images:', join(str(percentage*100), '%')))
      print('log.txt successfully written.')

  def writejson(self, output_path):
    try:
      metadata = open(os.path.join(output_path, 'input_metadata.json'), 'w')
      json.dump(self.img_dict, metadata, indent=1)
      metadata.close()
      print('input_metadata.json written successfully.')
    except:
      print('Unable to write input_metadata.json.')

  def add_entry(self, img, img_outname, img_dict):
    """
      Adds metadata entry to the metadictionary to be written.

      Params:
        img_dict: The dictionary to which to store metadata in.
        img: The directory path to the image file.
        img_outname: The accepted image's output file name.
    """
    res = Image.open(img).size
    ext = os.path.splitext(img)[1]
    par = os.path.abspath(os.path.join(img, os.pardir))
    self.img_dict[img_outname]=dict()
    self.img_dict[img_outname]['original_resolution'] = res
    self.img_dict[img_outname]['original_format'] = ext
    self.img_dict[img_outname]['original_path'] = par

  def reject_image(self, cur_img, input_path, output_path, size, img_blur_list, img_text_list=''):
    """
      All-encompassing function handling unusable images. Desired values for
      various thresholds can be tweaked. See: valid extensions, dimension minima,
      and blur threshold.

      Params:
        cur_img: The image to be examined.
        input_path: Directory path to input image folder.
        output_path: Directory path to output image folder.
        size: Desired size for which to qualify minimum size requirements.
        img_blur_list: The list of image paths classified as blurry.
        img_text_list: The list of image paths classified with detected text.

      Returns: Boolean
        True if the image should be rejected, and False if the image can be used.
    """
    reject_path = os.path.join(output_path, "rejected")
    cur_name = os.path.basename(os.path.normpath(cur_img))

    #Criteria 1: Is an image
    cur_ext = os.path.splitext(cur_img)[1]
    self.input_formats.add(cur_ext)
    
    start = time.time()
    if cur_ext not in self.valid_ext:
      print(cur_name, " REJECTED.", " Warning: Not an image.")
      shutil.copy(cur_img, reject_path)
      return True
    end = time.time()
    print(cur_name, "TIME FOR FORMAT ELAPSED: ", str(end-start))

    #Criteria 2: Sufficiently high resolution
    start = time.time()
    img = Image.open(cur_img)
    width, height = img.size
    self.validimg_input.append(cur_img) #Is a valid image, potentially rejectable
    
    self.input_widths.append(width)
    self.input_heights.append(height)

    if (width <= 0.8*size) or (height <= int(0.8*size)):
      print(cur_name, " REJECTED.", " Warning: Resolution too low.")
      shutil.copy(cur_img, reject_path)
      return True
    end = time.time()
    print(cur_name, "TIME FOR RESOLUTION ELAPSED: ", str(end-start))

    #Criteria 3: Is not in file path "blurry"
    start = time.time()
    if cur_name in self.blurry_input:
      print(cur_name, " REJECTED.", " Warning: Too blurry.")
      shutil.copy(cur_img, reject_path)
      return True
    end = time.time()
    print(cur_name, "TIME FOR BLURRY ELAPSED: ", str(end-start))

    #Criteria 6: Grayscale image
    start = time.time()
    img_info = cv2.imread(cur_img)
    #Look up more robust ways
    if len(img_info.shape) < 2:
      print(cur_name, "REJECTED.", "Warning: Grayscale image.")
      shutil.copy(cur_img, reject_path)
      return True
    end = time.time()
    print(cur_name, "TIME FOR GRAYSCALE ELAPSED: ", str(end-start))

    #Criteria 4: No human faces
    start = time.time()
    cur_img_fr = fr.load_image_file(cur_img)
    face_landmarks = fr.face_landmarks(cur_img_fr)

    if len(face_landmarks) != 0:
      print(cur_name," REJECTED.", " Warning: Faces detected.")
      shutil.copy(cur_img, reject_path)
      return True
    end = time.time()
    print(cur_name, "TIME FOR FACE ELAPSED: ", str(end-start))

    #Criteria 7: Text
    start = time.time()
    if self.text_detection(cur_img, 0.35) > 0:
      print(cur_name, "REJECTED.", "Warning: Text detected.")
      shutil.copy(cur_img, reject_path)
      return True
    end = time.time()
    print(cur_name, "TIME FOR TEXT ELAPSED: ", str(end-start))

    #Criteria 5: Sufficient image quality
    start = time.time()
    if brisque.score(img) >= 60:
      print(cur_name, "REJECTED.", "Warning: Low-quality image.")
      shutil.copy(cur_img, reject_path)
      return True
    end = time.time()
    print(cur_name, "TIME FOR BRISQUE ELAPSED: ", str(end-start))

    #Usable image
    return False

test = Pipeline(proj_path=proj_path, resize=1024)
print(test.size)

test.blurry_input = test.blur_detection(test.input_path, test.blur_thresh, split=True, v=False)

test.filter(test.input_path, test.output_path, test.size)

print(len(test.acc_img))
print(len(test.validimg_input))

# ~~~~~~~~~~~~~~~~~~~~~~~ TEST BLOCK ~~~~~~~~~~~~~~~~~~~~~~~

def text_detection(cur_img, confidence):
    east_path = os.path.join(proj_path, 'frozen_east_text_detection.pb')
    wid_new = 320
    hei_new = 320 #Adjustable

    img = cv2.imread(cur_img)
    img_orig = img.copy()

    (hei_orig, wid_orig) = img.shape[:2]
    wid_ratio = wid_orig / float(wid_new)
    hei_ratio = hei_orig / float (hei_new)

    img = cv2.resize(img, (wid_new, hei_new))
    #Grab dimensions?

    layerNames = [
      "feature_fusion/Conv_7/Sigmoid",
      "feature_fusion/concat_3"]

    net = cv2.dnn.readNet(east_path)
    blob = cv2.dnn.blobFromImage(img, 1.0, (wid_new, hei_new), \
      (123.68, 116.78, 103.94), swapRB=True, crop=False)
    net.setInput(blob)
    (scores, geometry) = net.forward(layerNames)

    (numRows, numCols) = scores.shape[2:4]
    rects = []
    confidences = []

    for y in range(0, numRows):
      # extract the scores (probabilities), followed by the geometrical data
      scoresData = scores[0, 0, y]
      xData0 = geometry[0, 0, y]
      xData1 = geometry[0, 1, y]
      xData2 = geometry[0, 2, y]
      xData3 = geometry[0, 3, y]
      anglesData = geometry[0, 4, y]

      # loop over the number of columns
      for x in range(0, numCols):
        # if our score does not have sufficient probability, ignore it
        if scoresData[x] < confidence:
          continue
        # compute the offset factor as our resulting feature maps will 4x smaller
        (offsetX, offsetY) = (x * 4.0, y * 4.0)
        # extract the rotation angle for the prediction and then compute sin, cos
        angle = anglesData[x]
        cos = np.cos(angle)
        sin = np.sin(angle)
        # use the geometry volume to derive the width and height of pred box
        h = xData0[x] + xData2[x]
        w = xData1[x] + xData3[x]
        # compute both the starting and ending (x, y)-coordinates for pred box
        endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))
        endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))
        startX = int(endX - w)
        startY = int(endY - h)
        # add the bounding box coordinates and probability score to resp. lists
        rects.append((startX, startY, endX, endY))
        confidences.append(scoresData[x])

    boxes = non_max_suppression(np.array(rects), probs=confidences)
    for (startX, startY, endX, endY) in boxes:
      # scale the bounding box coordinates based on the respective ratios
      startX = int(startX * wid_ratio)
      startY = int(startY * hei_ratio)
      endX = int(endX * wid_ratio)
      endY = int(endY * hei_ratio)
      # draw the bounding box on the image
      cv2.rectangle(img_orig, (startX, startY), (endX, endY), (0, 255, 0), 2)

    return len(rects)

input_path = os.path.join(proj_path, 'input')
sample_path = os.path.join(input_path, 'isopod')
mcd = os.path.join(sample_path, 'mcdhighres.jpg')

sampim = cv2.imread(mcd)
cv2.imwrite(os.path.join(input_path, 'sample.jpg'), sampim)

