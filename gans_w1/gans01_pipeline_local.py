# -*- coding: utf-8 -*-
"""gans01_pipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15UwRZ7o9GLcCg0FuYrVT9x1lhL0vkbhL
"""

import cv2
import os
from os import listdir
import sys
import argparse
from posixpath import join
import shutil

import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scipy

import face_recognition as fr
import imquality.brisque as brisque

import imutils
import time
from imutils.object_detection import non_max_suppression
from google.colab.patches import cv2_imshow

import PIL
print('PIL', PIL.__version__)
from PIL import Image

print(PIL.__version__)

sys_path = os.getcwd()
print('Path to training data: {}'.format(sys_path))

#TODO: Standardize input/output paths to make more sense.

valid_ext = ['.jpg', '.jpeg', '.png', '.tif', '.tiff', '.bmp', '.gif',\
               '.eps', '.raw', '.cr2', '.nef', '.orf', '.sr2','.webp']
input_valid = []
input_heights = []
input_widths = []
input_formats = set()
input_path = os.path.join(sys_path, 'input/')
output_path = os.path.join(sys_path, 'output/')
img_blur_list = []

def walk(input_path, files):
  """
    Searches for and collects directory pathways to files.

    Params:
      input_path: Directory path to input images.
      files: A list to store directory paths to valid files.

    Returns:????
      files: A list of pathways to valid files.
  """
  input_list = os.listdir(input_path)
  for item in input_list:
    if item == '.blurry' or item == '.sharp':
      continue
    if os.path.isdir(os.path.join(input_path,item)):
      walk(os.path.join(input_path, item), files)
    else:
      files.append(os.path.join(input_path, item))

def img_standardize(cur_img, size):
  """
    A function that crops and resizes the image being examined.

    Params:
      im: The image being standardized.
      size: The desired size to which to resize the input image to.
    Returns:
      img: PIL Image object of the standardized image.
  """
  img = Image.open(cur_img)
  width, height = img.size

  if (width > height):
    left_start = (width-height)/2
    img = img.crop((left_start, 0, left_start+height,height))
  elif (height > width):
    top_start = (height-width)/2
    img = img.crop((0, top_start, width, top_start+width))
  img = img.resize((size,size))

  return img

def blur_detection(input_path, thresh=30, split=True, v=True):
  """
    A function that detects and designates images as having an unacceptable
    amount of blurring.

    Params:
      input_path: Directory path to input images.
      thresh: Blurring threshold at which to classify as "blurry."
      split: Boolean denoting whether or nto to copy blurry images into a
        "blurry" subdirectory.
      verbose: Track progress verbosely.

    Returns:
      A list of image NAMES classified as blurry. MAKE PATHS?
  """
  input_list = []
  walk(input_path, input_list)
  input_list.sort()

  if split:
    shutil.rmtree(os.path.join(input_path, '.blurry'))
    shutil.rmtree(os.path.join(input_path, '.sharp'))
    blurry_path = os.path.join(input_path, '.blurry')
    sharp_path = os.path.join(input_path, '.sharp')
    os.makedirs(blurry_path, exist_ok=True)
    os.makedirs(sharp_path, exist_ok=True)

  lpcs = []
  for img_path in input_list:
    img_name = os.path.basename(os.path.normpath(img_path))
    if v:
      print(img_name, img_path)
    try:
      img_cv2 = cv2.imread(img_path)
      img_gray = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2GRAY)
      lpc = cv2.Laplacian(img_gray, cv2.CV_64F).var()
      lpcs.append(lpc)
      if v:
        print(lpc)
      if split:
        if lpc >= thresh:
          cv2.imwrite(os.path.join(sharp_path, img_name), img_cv2)
        else:
          cv2.imwrite(os.path.join(blurry_path, img_name), img_cv2)
    except:
      print("NOTE: " + img_name + " is not an image. Continuing.")

  #return lpcs
  return os.listdir(blurry_path)

def text_detection(cur_img, confidence):
  east_path = os.path.join(sys_path, 'frozen_east_text_detection.pb')
  wid_new = 320
  hei_new = 320 #Adjustable

  img = cv2.imread(cur_img)
  img_orig = img.copy()

  (hei_orig, wid_orig) = img.shape[:2]
  wid_ratio = wid_orig / float(wid_new)
  hei_ratio = hei_orig / float (hei_new)

  img = cv2.resize(img, (wid_new, hei_new))
  #Grab dimensions?

  layerNames = [
    "feature_fusion/Conv_7/Sigmoid",
    "feature_fusion/concat_3"]

  net = cv2.dnn.readNet(east_path)
  blob = cv2.dnn.blobFromImage(img, 1.0, (wid_new, hei_new), \
    (123.68, 116.78, 103.94), swapRB=True, crop=False)
  net.setInput(blob)
  (scores, geometry) = net.forward(layerNames)

  (numRows, numCols) = scores.shape[2:4]
  rects = []
  confidences = []

  for y in range(0, numRows):
    # extract the scores (probabilities), followed by the geometrical data
    scoresData = scores[0, 0, y]
    xData0 = geometry[0, 0, y]
    xData1 = geometry[0, 1, y]
    xData2 = geometry[0, 2, y]
    xData3 = geometry[0, 3, y]
    anglesData = geometry[0, 4, y]

    # loop over the number of columns
    for x in range(0, numCols):
      # if our score does not have sufficient probability, ignore it
      if scoresData[x] < confidence:
        continue
      # compute the offset factor as our resulting feature maps will 4x smaller
      (offsetX, offsetY) = (x * 4.0, y * 4.0)
      # extract the rotation angle for the prediction and then compute sin, cos
      angle = anglesData[x]
      cos = np.cos(angle)
      sin = np.sin(angle)
      # use the geometry volume to derive the width and height of pred box
      h = xData0[x] + xData2[x]
      w = xData1[x] + xData3[x]
      # compute both the starting and ending (x, y)-coordinates for pred box
      endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))
      endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))
      startX = int(endX - w)
      startY = int(endY - h)
      # add the bounding box coordinates and probability score to resp. lists
      rects.append((startX, startY, endX, endY))
      confidences.append(scoresData[x])

  boxes = non_max_suppression(np.array(rects), probs=confidences)
  for (startX, startY, endX, endY) in boxes:
    # scale the bounding box coordinates based on the respective ratios
    startX = int(startX * wid_ratio)
    startY = int(startY * hei_ratio)
    endX = int(endX * wid_ratio)
    endY = int(endY * hei_ratio)
    # draw the bounding box on the image
    cv2.rectangle(img_orig, (startX, startY), (endX, endY), (0, 255, 0), 2)

  return len(rects)

def writelog(input_list_valid, widths, heights, formats, acc):
  """
    Writes a text file containing statistics about the input dataset.

    Params:
      input_imgs: list of valid input image paths
      widths: list of image widths
      heights: list of image heights
      acc: number of accepted images
      rej: number of rejected images
  """
  num = len(input_list_valid)
  minw = np.min(widths)
  maxw = np.max(widths)
  minh = np.min(heights)
  maxh = np.max(heights)
  avw = np.average(widths)
  avh = np.average(heights)
  rej = num - acc
  percentage = (acc / (acc + rej))

  #Write stuff to file
  log_path = os.path.join(sys_path, '.logs')
  with open(os.path.join(log_path, 'log.txt'), 'w') as f:
    f.write(join("Number of valid images:", str(num)))
    f.write('\n')
    f.write('\n')

    f.write(join('Minimum input width:', str(minw)))
    f.write('\n')
    f.write(join('Maximum input width:', str(maxw)))
    f.write('\n')
    f.write('\n')

    f.write(join('Minimum input height:', str(minh)))
    f.write('\n')
    f.write(join('Maximum input height:', str(maxh)))
    f.write('\n')
    f.write('\n')

    f.write(join('Average input width:', str(avw)))
    f.write('\n')
    f.write(join('Average input width:', str(avh)))
    f.write('\n')
    f.write('\n')

    f.write(join('Percentage of accepted images:', join(str(percentage*100), '%')))
    print('log.txt successfully written.')

def add_entry(img, img_outname, img_dict):
  """
    Adds metadata entry to the metadictionary to be written.

    Params:
      img: The directory path to the image file.
      img_outname: The accepted image's output file name.
      img_dict: The dictionary to which to store metadata in.
  """
  res = Image.open(img).size
  ext = os.path.splitext(img)[1]
  par = os.path.abspath(os.path.join(img, os.pardir))
  img_dict[img_outname]=dict()
  img_dict[img_outname]['original_resolution'] = res
  img_dict[img_outname]['original_format'] = ext
  img_dict[img_outname]['original_path'] = par

def reject_image(cur_img, input_path, output_path, size, img_blur_list):
  """
    All-encompassing function handling unusable images. Desired values for
    various thresholds can be tweaked. See: valid extensions, dimension minima,
    and blur threshold.

    Params:
      cur_img: The image to be examined.
      input_path: Directory path to input image folder.
      output_path: Directory path to output image folder.
      size: Desired size for which to qualify minimum size requirements.
      img_blur_list: Given the list of blurry image paths, a reference list
        to which to classify dataset images as blurry.

    Returns: Boolean
      True if the image should be rejected, and False if the image can be used.
  """
  reject_folder = os.path.join(output_path, "rejected")
  cur_name = os.path.basename(os.path.normpath(cur_img))

  #Criteria 1: Is an image
  cur_ext = os.path.splitext(cur_img)[1]
  input_formats.add(cur_ext)

  if cur_ext not in valid_ext:
    print(cur_name, " REJECTED.", " Warning: Not an image.")
    shutil.copy(cur_img, reject_folder)
    return True

  #Criteria 2: Sufficiently high resolution
  print(cur_img)
  img = Image.open(cur_img)
  width, height = img.size
  input_valid.append(cur_img) #Is a valid image, potentially rejectable
  input_widths.append(width)
  input_heights.append(height)

  if (width <= 0.8*size) or (height <= int(0.8*size)):
    print(cur_name, " REJECTED.", " Warning: Resolution too low.")
    shutil.copy(cur_img, reject_folder)
    return True

  #Criteria 3: Is not in file path "blurry"
  if cur_name in img_blur_list:
    print(cur_name, " REJECTED.", " Warning: Too blurry.")
    shutil.copy(cur_img, reject_folder)
    return True

  #Criteria 6: Grayscale image
  img_info = cv2.imread(cur_img)
  #Look up more robust ways
  if len(img_info.shape) < 2:
    print(cur_name, "REJECTED.", "Warning: Grayscale image.")
    shutil.copy(cur_img, reject_folder)
    return True

  #Criteria 4: No human faces
  cur_img_fr = fr.load_image_file(cur_img)
  face_landmarks = fr.face_landmarks(cur_img_fr)

  if len(face_landmarks) != 0:
    print(cur_name," REJECTED.", " Warning: Faces detected.")
    shutil.copy(cur_img, reject_folder)
    return True

  #Criteria 5: Sufficient image quality
  if brisque.score(img) >= 60:
    print(cur_name, "REJECTED.", "Warning: Low-quality image.")
    shutil.copy(cur_img, reject_folder)
    return True

  #Criteria 7: Text
  if text_detection(cur_img, 0.5) > 0:
    print(cur_name, "REJECTED.", "Warning: Text detected.")
    shutil.copy(cur_img, reject_folder)
    return True

  #Usable image
  return False

def pipeline(input_path, output_path, size):
  """
    Given input data files, processes and sorts them according to usability.
    Main data pipeline function.

    Params:
      input_path: Directory path to input images.
      output_path: Directory path to output images.
      size: Desired length of square output image's edge.
  """
  #img_blur_list = blur_detection(input_path, thresh = 60, v=False)

  img_dict = dict()
  input_imgs = []
  walk(input_path, input_imgs)
  print("NUMBER OF POTENTIAL INPUTS: ", str(len(input_imgs)))

  img_display = []
  img_num = 0
  for img in input_imgs:
    # ~~~~~~~~~~~~~~~~ Start Loop ~~~~~~~~~~~~~~~~
    if reject_image(img, input_path, output_path, size, img_blur_list): continue

    cur_name = os.path.basename(os.path.normpath(img))
    img_outname = str(img_num).zfill(6)+'.png'
    print(cur_name, "ACCEPTED")

    #assemble dict ~~~
    add_entry(img, img_outname, img_dict)

    #crop, resize ~~~
    img_standardized = img_standardize(img, size)
    img_display.append(img_standardized)

    #copy over edited, accept/reject ~~~
    acc_folder = os.path.join(output_path, "accepted")
    accd_img = os.path.join(acc_folder, img_outname)
    img_standardized.save(accd_img)

    #Update valid img number
    img_num += 1
    # ~~~~~~~~~~~~~~~~ End Loop ~~~~~~~~~~~~~~~~

  #save to json to /output ~~~
  try:
    metadata = open(os.path.join(output_path, 'input_metadata.json'), 'w')
    json.dump(img_dict, metadata, indent=1)
    metadata.close()
    print('input_metadata.json written successfully.')
  except:
    print('Unable to write input_metadata.json.')

  #save log file
  writelog(input_valid, input_widths, input_heights, input_formats, len(img_display))

  # Peek at cropped images
  plt.figure(figsize=(10,10))
  for i in range(len(img_display)):
      plt.subplot(5,len(img_display)/5,i+1)
      plt.imshow(img_display[i])
      plt.axis('off')
  plt.show()

  return img_dict

img_blur_list = blur_detection(input_path, thresh = 60, v=False)

def test_pipeline():
  input_path = sys_path + 'input/'
  output_path = sys_path + 'output/'

  print(pipeline(input_path, output_path, 300))

test_pipeline()
